{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb560f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef81dcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the model/weight files\n",
    "\n",
    "FACE_PROTO = r\"C:\\Users\\Admin\\Downloads\\opencv_face_detector.pbtxt\"\n",
    "FACE_MODEL = r\"C:\\Users\\Admin\\Downloads\\opencv_face_detector_uint8.pb\"\n",
    "\n",
    "AGE_PROTO = r\"C:\\Users\\Admin\\Downloads\\age_deploy.prototxt\"\n",
    "AGE_MODEL = r\"C:\\Users\\Admin\\Downloads\\age_net.caffemodel\"\n",
    "\n",
    "GENDER_PROTO = r\"C:\\Users\\Admin\\Downloads\\gender_deploy.prototxt\"\n",
    "GENDER_MODEL = r\"C:\\Users\\Admin\\Downloads\\gender_net.caffemodel\"\n",
    "\n",
    "# Load network\n",
    "FACE_NET = cv2.dnn.readNet(FACE_MODEL, FACE_PROTO)\n",
    "AGE_NET = cv2.dnn.readNet(AGE_MODEL, AGE_PROTO)\n",
    "GENDER_NET = cv2.dnn.readNet(GENDER_MODEL, GENDER_PROTO)\n",
    "\n",
    "MODEL_MEAN_VALUES = (78.4263377603, 87.7689143744, 114.895847746)\n",
    "AGE_LIST = [\"(0-2)\", \"(4-6)\", \"(8-12)\", \"(15-20)\", \"(25-32)\", \"(38-43)\", \"(48-53)\", \"(60-100)\"]\n",
    "GENDER_LIST = [\"Male\", \"Female\"]\n",
    "\n",
    "box_padding = 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b2d04c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Getting the bounding box coordinates\n",
    "\n",
    "def get_face_box (net, frame, conf_threshold = 0.7):\n",
    "  frame_copy = frame.copy()\n",
    "  frame_height = frame_copy.shape[0]\n",
    "  frame_width = frame_copy.shape[1]\n",
    "  blob = cv2.dnn.blobFromImage(frame_copy, 1.0, (300, 300), [104, 117, 123], True, False)\n",
    "\n",
    "  net.setInput(blob)\n",
    "  detections = net.forward()\n",
    "  boxes = []\n",
    "\n",
    "  for i in range(detections.shape[2]):\n",
    "    confidence = detections[0, 0, i, 2]\n",
    "\n",
    "    if confidence > conf_threshold:\n",
    "      x1 = int(detections[0, 0, i, 3] * frame_width)\n",
    "      y1 = int(detections[0, 0, i, 4] * frame_height)\n",
    "      x2 = int(detections[0, 0, i, 5] * frame_width)\n",
    "      y2 = int(detections[0, 0, i, 6] * frame_height)\n",
    "      boxes.append([x1, y1, x2, y2])\n",
    "      cv2.rectangle(frame_copy, (x1, y1), (x2, y2), (0, 255, 0), int(round(frame_height / 150)), 8)\n",
    "\n",
    "  return frame_copy, boxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be16035b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender: Male, conf: 1.000\n",
      "Age: (25-32), conf: 0.513\n"
     ]
    }
   ],
   "source": [
    "# # Predicting age and gender\n",
    "\n",
    "def age_gender_detector (input_path):\n",
    "  image = cv2.imread(r\"C:\\Users\\Admin\\Downloads\\virat.jpg\")\n",
    "  resized_image = cv2.resize(image, (640, 480))\n",
    "\n",
    "  frame = resized_image.copy()\n",
    "  frame_face, boxes = get_face_box(FACE_NET, frame)\n",
    "\n",
    "  for box in boxes:\n",
    "    face = frame[max(0, box[1] - box_padding):min(box[3] + box_padding, frame.shape[0] - 1),       max(0, box[0] - box_padding):min(box[2] + box_padding, frame.shape[1] - 1)]\n",
    "\n",
    "    blob = cv2.dnn.blobFromImage(face, 1.0, (227, 227), MODEL_MEAN_VALUES, swapRB = False)\n",
    "    GENDER_NET.setInput(blob)\n",
    "    gender_predictions = GENDER_NET.forward()\n",
    "    gender = GENDER_LIST[gender_predictions[0].argmax()]\n",
    "    print(\"Gender: {}, conf: {:.3f}\".format(gender, gender_predictions[0].max()))\n",
    "\n",
    "    AGE_NET.setInput(blob)\n",
    "    age_predictions = AGE_NET.forward()\n",
    "    age = AGE_LIST[age_predictions[0].argmax()]\n",
    "    print(\"Age: {}, conf: {:.3f}\".format(age, age_predictions[0].max()))\n",
    "\n",
    "    label = \"{},{}\".format(gender, age)\n",
    "    cv2.putText(frame_face, label, (box[0], box[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "  return frame_face\n",
    "\n",
    "\n",
    "# # Writing main\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  output = age_gender_detector(sys.argv[1])\n",
    "  cv2.imwrite(\"output/output.jpg\", output)\n",
    "  cv2.imshow(\"Output\", output)\n",
    "\n",
    "  cv2.waitKey(0)\n",
    "  cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066db14f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
